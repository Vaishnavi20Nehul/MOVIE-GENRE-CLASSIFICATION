{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855b760b-005c-4383-abc8-f23e03d5ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopword: Package 'stopword' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopword')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fa5ba9-fcb1-4e1b-8cbe-7c716980b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"train_data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729f158-e117-4d85-8914-3e552dd17047",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937176e7-7861-4197-9eaf-3c05b4bb7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep=\":::\", engine=\"python\", header=None)\n",
    "df.columns = [\"id\", \"title\", \"genre\", \"plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b11176-53a9-4bb9-af12-c52337af77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (54214, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c153d3c5-f2d1-4694-8499-823fc73e7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: <bound method NDFrame.head of           id                                         title          genre  \\\n",
      "0          1                 Oscar et la dame rose (2009)          drama    \n",
      "1          2                                 Cupid (1997)       thriller    \n",
      "2          3             Young, Wild and Wonderful (1980)          adult    \n",
      "3          4                        The Secret Sin (1915)          drama    \n",
      "4          5                       The Unrecovered (2007)          drama    \n",
      "...      ...                                           ...            ...   \n",
      "54209  54210                              \"Bonino\" (1953)         comedy    \n",
      "54210  54211                  Dead Girls Don't Cry (????)         horror    \n",
      "54211  54212    Ronald Goedemondt: Ze bestaan echt (2008)    documentary    \n",
      "54212  54213                     Make Your Own Bed (1944)         comedy    \n",
      "54213  54214   Nature's Fury: Storm of the Century (2006)        history    \n",
      "\n",
      "                                                    plot  \n",
      "0       Listening in to a conversation between his do...  \n",
      "1       A brother and sister with a past incestuous r...  \n",
      "2       As the bus empties the students for their fie...  \n",
      "3       To help their unemployed father make ends mee...  \n",
      "4       The film's title refers not only to the un-re...  \n",
      "...                                                  ...  \n",
      "54209   This short-lived NBC live sitcom centered on ...  \n",
      "54210   The NEXT Generation of EXPLOITATION. The sist...  \n",
      "54211   Ze bestaan echt, is a stand-up comedy about g...  \n",
      "54212   Walter and Vivian live in the country and hav...  \n",
      "54213   On Labor Day Weekend, 1935, the most intense ...  \n",
      "\n",
      "[54214 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(\"head:\",df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36751dae-6530-4035-8211-b8e0cc0fcb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total genres: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal genres:\", df[\"genre\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c0d5d2-3db9-49bd-b264-0a6055abb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 genres:\n",
      "\n",
      "genre\n",
      "drama           13613\n",
      "documentary     13096\n",
      "comedy           7447\n",
      "short            5073\n",
      "horror           2204\n",
      "thriller         1591\n",
      "action           1315\n",
      "western          1032\n",
      "reality-tv        884\n",
      "family            784\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 10 genres:\\n\")\n",
    "print(df[\"genre\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc23c3e-512a-4c8a-954c-a87592efdafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique genre: 0               drama \n",
      "1            thriller \n",
      "2               adult \n",
      "3               drama \n",
      "4               drama \n",
      "             ...      \n",
      "54209          comedy \n",
      "54210          horror \n",
      "54211     documentary \n",
      "54212          comedy \n",
      "54213         history \n",
      "Name: genre, Length: 54214, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"number of unique genre:\",df.genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16608a3b-d30b-4781-a080-c61722b3e8db",
   "metadata": {},
   "source": [
    "# STEP 2: Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd33343-24c0-42b7-b2c5-13486027d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8539436-06b5-42e9-ab4d-0a26ee36f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d651abec-27f7-47cc-8d82-8574cbd35789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning shape: (54214, 4)\n"
     ]
    }
   ],
   "source": [
    "# Strip extra spaces\n",
    "df[\"plot\"] = df[\"plot\"].str.strip()\n",
    "df[\"genre\"] = df[\"genre\"].str.strip()\n",
    "\n",
    "print(\"After cleaning shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7127f0-57fa-4031-bb70-d32b78f1c167",
   "metadata": {},
   "source": [
    "# STEP 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8152051-5a21-450c-b6a7-0a687ba6cb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119ab5f1-a042-44bb-970b-8ba796930f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yourselves', 'its', 'how', \"i'll\", \"she's\", 'being', \"don't\", 'am', 'shan', 'needn']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "print(list(stop_words)[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87605200-2ab1-454e-83a5-84e01aff88c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                plot  \\\n",
      "0  Listening in to a conversation between his doc...   \n",
      "1  A brother and sister with a past incestuous re...   \n",
      "2  As the bus empties the students for their fiel...   \n",
      "3  To help their unemployed father make ends meet...   \n",
      "4  The film's title refers not only to the un-rec...   \n",
      "\n",
      "                                          clean_plot  \n",
      "0  listening conversation doctor parent yearold o...  \n",
      "1  brother sister past incestuous relationship cu...  \n",
      "2  bus empty student field trip museum natural hi...  \n",
      "3  help unemployed father make end meet edith twi...  \n",
      "4  film title refers unrecovered body ground zero...  \n"
     ]
    }
   ],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#Apply cleaning\n",
    "df[\"clean_plot\"]=df[\"plot\"].apply(clean_text)\n",
    "print(df[[\"plot\",\"clean_plot\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6081cd-da22-471f-b652-1238bef7431a",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d6dab1-c2f6-45ca-afce-e728b2bcc185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: (43371,)\n",
      "Training samples: (10843,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=df[\"clean_plot\"]\n",
    "y=df[\"genre\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
    "print(\"Training samples:\",X_train.shape)\n",
    "print(\"Training samples:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0359f-d877-4e95-a9f5-2ce88b17fb76",
   "metadata": {},
   "source": [
    "# TF-IDF VECTORIZATION:Term Frequency-inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd9e0319-4959-4cfc-b559-e077e03f7f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (43371, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf=TfidfVectorizer(max_features=5000,ngram_range=(1,2))\n",
    "\n",
    "X_train_tfidf=tfidf.fit_transform(X_train)\n",
    "X_test_tfidf=tfidf.transform(X_test)\n",
    "print(\"TF-IDF shape:\",X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15f696-fb4a-4bd9-a5b9-724597189a9a",
   "metadata": {},
   "source": [
    "# Train Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99263e6b-3158-4c51-9059-13e056c4576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model=MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf,y_train)\n",
    "nb_preds=nb_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dea37c0b-2d53-4565-91a4-e71db71752c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model=LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf,y_train)\n",
    "\n",
    "lr_preds=lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab19cb-aa50-4867-8033-7d8b789b2311",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba9c1336-a6fd-4e56-9c0b-3d0fd414ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5207046020474039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.66      0.10      0.17       263\n",
      "       adult       0.69      0.09      0.16       118\n",
      "   adventure       0.64      0.06      0.11       155\n",
      "   animation       0.00      0.00      0.00       100\n",
      "   biography       0.00      0.00      0.00        53\n",
      "      comedy       0.51      0.44      0.47      1490\n",
      "       crime       0.00      0.00      0.00       101\n",
      " documentary       0.57      0.88      0.69      2619\n",
      "       drama       0.46      0.81      0.58      2723\n",
      "      family       0.00      0.00      0.00       157\n",
      "     fantasy       0.00      0.00      0.00        65\n",
      "   game-show       1.00      0.18      0.30        39\n",
      "     history       0.00      0.00      0.00        49\n",
      "      horror       0.77      0.34      0.47       441\n",
      "       music       0.71      0.08      0.15       146\n",
      "     musical       0.00      0.00      0.00        55\n",
      "     mystery       0.00      0.00      0.00        64\n",
      "        news       0.00      0.00      0.00        36\n",
      "  reality-tv       0.00      0.00      0.00       177\n",
      "     romance       0.00      0.00      0.00       134\n",
      "      sci-fi       0.86      0.05      0.09       129\n",
      "       short       0.56      0.12      0.20      1015\n",
      "       sport       0.70      0.08      0.15        86\n",
      "   talk-show       1.00      0.01      0.03        78\n",
      "    thriller       0.39      0.02      0.04       318\n",
      "         war       0.00      0.00      0.00        26\n",
      "     western       0.97      0.54      0.69       206\n",
      "\n",
      "    accuracy                           0.52     10843\n",
      "   macro avg       0.39      0.14      0.16     10843\n",
      "weighted avg       0.51      0.52      0.44     10843\n",
      "\n",
      "Logistic Regression Accuracy: 0.5784377017430601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.48      0.26      0.34       263\n",
      "       adult       0.72      0.29      0.41       118\n",
      "   adventure       0.55      0.12      0.19       155\n",
      "   animation       0.50      0.08      0.14       100\n",
      "   biography       0.00      0.00      0.00        53\n",
      "      comedy       0.53      0.59      0.56      1490\n",
      "       crime       0.14      0.02      0.03       101\n",
      " documentary       0.67      0.85      0.75      2619\n",
      "       drama       0.54      0.77      0.63      2723\n",
      "      family       0.45      0.09      0.15       157\n",
      "     fantasy       0.00      0.00      0.00        65\n",
      "   game-show       0.86      0.49      0.62        39\n",
      "     history       0.00      0.00      0.00        49\n",
      "      horror       0.64      0.58      0.61       441\n",
      "       music       0.66      0.42      0.51       146\n",
      "     musical       0.67      0.04      0.07        55\n",
      "     mystery       0.33      0.02      0.03        64\n",
      "        news       0.67      0.06      0.10        36\n",
      "  reality-tv       0.41      0.17      0.24       177\n",
      "     romance       0.14      0.01      0.01       134\n",
      "      sci-fi       0.59      0.29      0.39       129\n",
      "       short       0.45      0.32      0.37      1015\n",
      "       sport       0.51      0.22      0.31        86\n",
      "   talk-show       0.53      0.13      0.21        78\n",
      "    thriller       0.36      0.12      0.18       318\n",
      "         war       0.00      0.00      0.00        26\n",
      "     western       0.88      0.65      0.75       206\n",
      "\n",
      "    accuracy                           0.58     10843\n",
      "   macro avg       0.46      0.24      0.28     10843\n",
      "weighted avg       0.55      0.58      0.54     10843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_preds))\n",
    "print(classification_report(y_test, nb_preds))\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_preds))\n",
    "print(classification_report(y_test, lr_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c4523-6094-490e-aee3-4606536ec244",
   "metadata": {},
   "source": [
    "# Test on Your Own Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa0354d-7c91-485b-a3fd-2afe9553f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Prediction: drama\n",
      "Logistic Regression Prediction: short\n"
     ]
    }
   ],
   "source": [
    "sample = [\"A young boy discovers he has magical powers and attends a wizard school\"]\n",
    "\n",
    "sample_clean = clean_text(sample[0])\n",
    "sample_vec = tfidf.transform([sample_clean])\n",
    "\n",
    "print(\"Naive Bayes Prediction:\", nb_model.predict(sample_vec)[0])\n",
    "print(\"Logistic Regression Prediction:\", lr_model.predict(sample_vec)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2425a-de69-4051-b5df-e5cea457f529",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9d6290d-2b31-40ac-9e80-2251df71bb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr_model, \"movie_genre_model.pkl\")\n",
    "joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec2036-317d-49c0-b9d8-2cb251ae669c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
